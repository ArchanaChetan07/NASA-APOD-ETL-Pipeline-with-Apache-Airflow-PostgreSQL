[2025-04-18T20:04:44.314+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nasa_apod_postgres.load_data_to_postgres manual__2025-04-18T20:04:40.277027+00:00 [queued]>
[2025-04-18T20:04:44.319+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nasa_apod_postgres.load_data_to_postgres manual__2025-04-18T20:04:40.277027+00:00 [queued]>
[2025-04-18T20:04:44.319+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-04-18T20:04:44.327+0000] {taskinstance.py:2191} INFO - Executing <Task(_PythonDecoratedOperator): load_data_to_postgres> on 2025-04-18 20:04:40.277027+00:00
[2025-04-18T20:04:44.330+0000] {standard_task_runner.py:60} INFO - Started process 380 to run task
[2025-04-18T20:04:44.332+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'nasa_apod_***', 'load_data_to_***', 'manual__2025-04-18T20:04:40.277027+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/etl.py', '--cfg-path', '/tmp/tmpu077wvus']
[2025-04-18T20:04:44.334+0000] {standard_task_runner.py:88} INFO - Job 15: Subtask load_data_to_***
[2025-04-18T20:04:44.342+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.8/site-packages/airflow/settings.py:194 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-04-18T20:04:44.361+0000] {task_command.py:423} INFO - Running <TaskInstance: nasa_apod_postgres.load_data_to_postgres manual__2025-04-18T20:04:40.277027+00:00 [running]> on host 4d4fb407ffc6
[2025-04-18T20:04:44.411+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='nasa_apod_***' AIRFLOW_CTX_TASK_ID='load_data_to_***' AIRFLOW_CTX_EXECUTION_DATE='2025-04-18T20:04:40.277027+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-04-18T20:04:40.277027+00:00'
[2025-04-18T20:04:44.417+0000] {base.py:83} INFO - Using connection ID 'my_***_connection' for task execution.
[2025-04-18T20:04:44.419+0000] {sql.py:450} INFO - Running statement: 
        INSERT INTO apod_data (title, explanation, url, date, media_type)
        VALUES (%s, %s, %s, %s, %s);
        , parameters: ('Comet C/2025 F2 SWAN', "In late March, the comet now designated C/2025 F2 SWAN was found independently by citizen scientists Vladimir Bezugly, Michael Mattiazzo, and Rob Matson while examining publicly available image data from the Solar Wind ANisotropies (SWAN) camera on the sun-staring SOHO spacecraft. Comet SWAN's coma, its greenish color a signature of diatomic carbon molecules fluorescing in sunlight, is at lower left in this telescopic image. SWAN's faint ion tail extends nearly two degrees toward the upper right across the field of view. The interplanetary scene was captured in clear but moonlit skies from June Lake, California on April 14. Seen against background of stars toward the constellation Andromeda, the comet was then some 10 light-minutes from our fair planet. Now a target for binoculars and small telescopes in northern hemisphere morning skies this comet SWAN is headed for a perihelion, its closest approach to the Sun, on May 1. That will bring this visitor from the distant Oort cloud almost as close to the Sun as the orbit of inner planet Mercury.", 'https://apod.nasa.gov/apod/image/2504/C2025_F2SWAN_20250414_DEBartlett1024.jpg', '2025-04-18', 'image')
[2025-04-18T20:04:44.420+0000] {sql.py:459} INFO - Rows affected: 1
[2025-04-18T20:04:44.421+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-04-18T20:04:44.425+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=nasa_apod_***, task_id=load_data_to_***, execution_date=20250418T200440, start_date=20250418T200444, end_date=20250418T200444
[2025-04-18T20:04:44.464+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-04-18T20:04:44.474+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
